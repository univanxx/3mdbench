{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp2id = {'unsatisfactory': 0, 'satisfactory': 1, 'excellent': 2}\n",
    "\n",
    "COMPlAINTS_PATH = \"/home/jovyan/isviridov/gm/3mdbench/data/complaints.json\"\n",
    "GLOBAL_DIALOGUES_PATH = \"/home/jovyan/isviridov/gm/3mdbench/results\"\n",
    "GLOBAL_ASSESSMENTS_PATH = \"/home/jovyan/isviridov/gm/3mdbench/results/assessment\"\n",
    "GLOBAL_OBTAINED_DIAGNOSES_PATH = \"/home/jovyan/isviridov/gm/3mdbench/results/assessment/diags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COMPlAINTS_PATH, 'r') as f:\n",
    "    complaints = json.load(f)\n",
    "\n",
    "true_diags = set()\n",
    "for complaint in complaints:\n",
    "    true_diags.add(complaints[complaint]['diagnosis'].lower())\n",
    "true_diags = list(true_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doctor_replics(dialogue):\n",
    "    utterances = [x.strip().lower() for x in re.split('Patient:|Doctor:|DIAG:', dialogue) if len(x.strip()) > 0]\n",
    "    doc_utterances = [utterances[i] for i in range(1, len(utterances), 2)]\n",
    "    return doc_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replace(answer):\n",
    "    try:\n",
    "        return int(answer)\n",
    "    except ValueError:\n",
    "        answer = \"\".join(re.findall(r\"[a-zA-Z]+\", answer.lower()))\n",
    "        if answer == \"no\":\n",
    "            return 0\n",
    "        elif answer == \"yes\":\n",
    "            return 1\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diags(preds):\n",
    "    diags = [diag.strip() for diag in preds.split(',')]\n",
    "    return diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_diags(preds):\n",
    "    diags = [diag.strip() for diag in preds.split(',')]\n",
    "    for i, diag_i in enumerate(diags):\n",
    "        if \"herpes\" in diag_i or \"cold sore\" in diag_i or \"hsv\" in diag_i:\n",
    "            diags[i] = \"herpes\"\n",
    "        elif \"grown\" in diag_i and \"nail\" in diag_i:\n",
    "            diags[i] = \"ingrown nail\"\n",
    "        elif \"hives\" in diag_i or \"urticaria\" in diag_i:\n",
    "            diags[i] = \"hives\"\n",
    "        elif \"cavities\" in diag_i or \"caries\" in diag_i:\n",
    "            diags[i] = \"caries\"\n",
    "        elif 'solar keratosis' in diag_i:\n",
    "            diags[i] = 'actinic keratosis'\n",
    "        elif \"wart\" in diag_i:\n",
    "            diags[i] = \"warts\"\n",
    "        elif 'atopic dermatitis' in diag_i:\n",
    "            diags[i] = \"eczema\"\n",
    "        elif 'gum disease' in diag_i:\n",
    "            diags[i] = 'gingivitis'\n",
    "        elif \"nail\" in diag_i and \"fun\" in diag_i:\n",
    "            diags[i] = \"onychomycosis\"\n",
    "        elif \"subungual hematoma\" in diag_i or \"onychodystrophy\" in diag_i:\n",
    "            diags[i] = \"nail dystrophy\"\n",
    "        elif \"dandruff\" in diag_i:\n",
    "            diags[i] = 'seborrheic dermatitis'\n",
    "        elif \"varicella\" in diag_i:\n",
    "            diags[i] = \"chickenpox\"\n",
    "        elif \"hordeolum\" in diag_i:\n",
    "            diags[i] = \"stye\"\n",
    "        elif \"tinea versicolor\" in diag_i or \"ringworm\" in diag_i or \"fungal infection\" in diag_i:\n",
    "            diags[i] = \"mycosis\"\n",
    "        elif \"tartar buildup\" in diag_i or \"plaque buildup\" in diag_i:\n",
    "            diags[i] = \"dental calculus\"\n",
    "        elif \"aphthous ulcers\" in diag_i:\n",
    "            diags[i] = \"stomatitis\"\n",
    "        else:\n",
    "            continue\n",
    "    return diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dialogue_metrics(assessments_list, dialogues_path, model_name):\n",
    "    assessments, failed_assessments, failed_cases, is_failed = [], [], [], []\n",
    "    for dialogue in assessments_list:\n",
    "        dialogue_case = dialogue.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "        with open(dialogue, 'r') as f:\n",
    "            assessment_data = json.load(f)\n",
    "\n",
    "        assessment = assessment_data[dialogue_case][\"assessment\"].replace(\"```\", '').replace(\"json\", '').replace(\"python\", '')\n",
    "        assessment = assessment[:assessment.rfind('}')+1]\n",
    "        try:\n",
    "            assessment = ast.literal_eval(assessment)[\"Doctor assessment\"]\n",
    "            answ = [int(get_replace(assessment[\"Diagnostic abilities\"][\"0.1\"])),\n",
    "                    int(get_replace(assessment[\"Medical Interviewing Skills\"][\"1.1\"])),\n",
    "                    int(get_replace(assessment[\"Medical Interviewing Skills\"][\"1.2\"])),\n",
    "                    int(get_replace(assessment[\"Medical Interviewing Skills\"][\"1.3\"])),\n",
    "                    int(get_replace(assessment[\"Humanistic Care\"][\"3.1\"])),\n",
    "                    int(get_replace(assessment[\"Humanistic Care\"][\"3.2\"])),\n",
    "                    int(get_replace(assessment[\"Comprehensive Diagnostic and Treatment Abilities\"][\"4.1\"])),\n",
    "                    int(get_replace(assessment[\"Comprehensive Diagnostic and Treatment Abilities\"][\"4.2\"])),\n",
    "                    int(comp2id[assessment[\"Overall Clinical Competence\"][\"5.1\"].lower()]),\n",
    "                    int(get_replace(assessment[\"Slayness\"][\"6.1\"]))\n",
    "            ]\n",
    "            assessments.append(answ)\n",
    "        except SyntaxError:\n",
    "            failed_assessments.append(dialogue)\n",
    "            failed_cases.append(assessment)\n",
    "            with open(f'{dialogues_path}/{model_name}/case_{dialogue_case}.json', 'r') as f:\n",
    "                dialogue_text = json.load(f)\n",
    "            is_failed.append(not dialogue_text[dialogue_case][\"dialogue_ended\"])\n",
    "    assert np.sum(is_failed) == len(failed_assessments), \"You have some unassessed finished dialogues!\"\n",
    "    return assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"llama_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dialogue metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessed_dialogues = glob.glob(os.path.join(GLOBAL_ASSESSMENTS_PATH, experiment_name) + \"/*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(count_dialogue_metrics(assessed_dialogues, GLOBAL_DIALOGUES_PATH, experiment_name))\n",
    "res = list(map(lambda x: float(round(x, 3)), np.mean(res, axis=0)))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = glob.glob(f\"{GLOBAL_OBTAINED_DIAGNOSES_PATH}/{experiment_name}/*.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_diags = {}\n",
    "\n",
    "for case_i in cases:\n",
    "    k = case_i.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "    try:\n",
    "        with open(case_i, 'r') as f:\n",
    "            res = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        pred_diags[k] = res[k][\"diags\"].replace('\\n', '').replace('`', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds, model_gts, failed_diags = [], [], 0\n",
    "\n",
    "for k in pred_diags:\n",
    "    diags_list = get_correct_diags(pred_diags[k])\n",
    "    if diags_list == [\"none\"]:\n",
    "        failed_diags += 1\n",
    "        continue\n",
    "    else:\n",
    "        for pred_diag in diags_list:\n",
    "            model_preds.append(pred_diag)\n",
    "            # adding ground truth label multiple times in case of multiple predictions for the same case\n",
    "            model_gts.append(complaints[k]['diagnosis'].lower())\n",
    "failed_diags /= len(pred_diags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(model_gts, model_preds, average=\"weighted\", labels=list(true_diags)), failed_diags*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
